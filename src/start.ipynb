{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Untitled15.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "metadata": {
        "id": "RJJ-gzxJdnkT"
      },
      "source": [
        "import torch\r\n",
        "import torch.nn.functional as F\r\n",
        "import torch.nn as nn\r\n",
        "import torchvision\r\n",
        "from torchvision import transforms\r\n",
        "import numpy as np\r\n",
        "from torchsummary import summary as summary_"
      ],
      "execution_count": 92,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ke9Op9qsdqHB"
      },
      "source": [
        "class selfModule(nn.Module):\r\n",
        "    def __init__(self):\r\n",
        "        super(selfModule, self).__init__()\r\n",
        "        self.model = nn.Sequential(\r\n",
        "            nn.Conv2d(1, 32, 3, padding=1, stride=2),\r\n",
        "            nn.Tanh(),\r\n",
        "            nn.MaxPool2d(2),\r\n",
        "            nn.Conv2d(32, 64, 3, padding=1, stride=2),\r\n",
        "            nn.Tanh(),\r\n",
        "            nn.MaxPool2d(2),\r\n",
        "            nn.Flatten(),\r\n",
        "            nn.Linear(256,200),\r\n",
        "            nn.Tanh(),\r\n",
        "            nn.Linear(200,10),\r\n",
        "            nn.LogSoftmax()\r\n",
        "        )\r\n",
        "        \r\n",
        "    def forward(self, x):\r\n",
        "        out = self.model(x)\r\n",
        "        return out"
      ],
      "execution_count": 104,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kJ5IyG9bs2CY",
        "outputId": "33f1310e-0e0f-442b-f325-334385ffcda9"
      },
      "source": [
        "model = selfModule()\r\n",
        "summary_(model,(1,28,28))"
      ],
      "execution_count": 105,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "----------------------------------------------------------------\n",
            "        Layer (type)               Output Shape         Param #\n",
            "================================================================\n",
            "            Conv2d-1           [-1, 32, 14, 14]             320\n",
            "              Tanh-2           [-1, 32, 14, 14]               0\n",
            "         MaxPool2d-3             [-1, 32, 7, 7]               0\n",
            "            Conv2d-4             [-1, 64, 4, 4]          18,496\n",
            "              Tanh-5             [-1, 64, 4, 4]               0\n",
            "         MaxPool2d-6             [-1, 64, 2, 2]               0\n",
            "           Flatten-7                  [-1, 256]               0\n",
            "            Linear-8                  [-1, 200]          51,400\n",
            "              Tanh-9                  [-1, 200]               0\n",
            "           Linear-10                   [-1, 10]           2,010\n",
            "       LogSoftmax-11                   [-1, 10]               0\n",
            "================================================================\n",
            "Total params: 72,226\n",
            "Trainable params: 72,226\n",
            "Non-trainable params: 0\n",
            "----------------------------------------------------------------\n",
            "Input size (MB): 0.00\n",
            "Forward/backward pass size (MB): 0.13\n",
            "Params size (MB): 0.28\n",
            "Estimated Total Size (MB): 0.41\n",
            "----------------------------------------------------------------\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "oOdEIh64vL_L",
        "outputId": "091b4414-dc91-4d61-a95a-2880cd27d254"
      },
      "source": [
        "model.state_dict()"
      ],
      "execution_count": 107,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "OrderedDict([('model.0.weight',\n",
              "              tensor([[[[ 6.9470e-02, -3.2027e-01,  6.9798e-02],\n",
              "                        [ 1.5328e-01,  2.3020e-01,  1.2463e-01],\n",
              "                        [-2.5464e-02, -1.7015e-01, -6.7813e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.9467e-02,  1.3905e-01,  8.0599e-02],\n",
              "                        [ 1.8126e-01, -1.2514e-01, -8.9499e-02],\n",
              "                        [-3.2010e-01,  3.2651e-03,  9.0117e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.3808e-01, -3.1156e-01, -1.0573e-01],\n",
              "                        [-2.0043e-01,  2.5320e-01,  8.8500e-02],\n",
              "                        [-9.1475e-02, -2.7554e-01, -1.6991e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 2.6915e-01, -7.9201e-02, -3.2234e-01],\n",
              "                        [-5.9149e-03,  1.3894e-01,  1.0786e-01],\n",
              "                        [ 1.8040e-01,  3.6466e-02,  2.9750e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.0096e-01, -1.3276e-01, -1.9667e-01],\n",
              "                        [-2.6377e-01, -2.5365e-03,  1.5673e-01],\n",
              "                        [-1.6158e-01,  3.3308e-01,  1.1573e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-5.7720e-02,  1.3820e-01,  2.4923e-02],\n",
              "                        [ 2.3710e-01,  1.4773e-01,  5.6442e-02],\n",
              "                        [-4.8012e-02,  2.5394e-01,  1.2189e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.4643e-01,  3.2227e-01,  1.0462e-01],\n",
              "                        [-2.8986e-01,  2.2961e-01,  2.4134e-01],\n",
              "                        [-2.7234e-01, -4.5617e-02,  3.0015e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.2093e-02, -2.6057e-01, -1.5375e-01],\n",
              "                        [ 2.5824e-01, -1.2209e-01, -2.2857e-01],\n",
              "                        [ 2.1729e-01, -2.4976e-01,  9.4772e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.2918e-01, -4.1036e-02, -1.7013e-01],\n",
              "                        [ 1.3370e-02, -2.0122e-01, -1.3403e-01],\n",
              "                        [ 9.7573e-02, -3.1498e-01,  2.4296e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.8784e-01,  2.5658e-01, -2.7937e-01],\n",
              "                        [ 2.0372e-01, -1.4686e-02,  1.2973e-02],\n",
              "                        [ 1.1335e-01, -1.5186e-01,  2.4871e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.7018e-01, -1.4857e-01, -3.5959e-03],\n",
              "                        [ 2.7439e-01,  1.3772e-01,  2.9907e-01],\n",
              "                        [ 1.5445e-01,  6.8162e-02,  2.4348e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-3.0573e-01, -5.6426e-06,  4.4567e-02],\n",
              "                        [ 1.6514e-01,  6.3931e-02,  2.1458e-01],\n",
              "                        [-1.0961e-01,  2.9967e-01,  1.0360e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 2.7490e-01, -8.6096e-02,  6.9140e-02],\n",
              "                        [-2.4637e-01, -1.2826e-02,  2.3692e-01],\n",
              "                        [ 2.1823e-01,  1.3879e-01,  5.3355e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 6.7210e-02,  2.0160e-01, -2.6087e-01],\n",
              "                        [-9.2778e-02,  7.7134e-02,  9.4353e-02],\n",
              "                        [ 2.2163e-01, -9.9431e-02, -1.6904e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 2.4898e-01, -1.4445e-01, -8.3776e-02],\n",
              "                        [-1.7663e-02, -5.1974e-02, -9.0870e-02],\n",
              "                        [ 1.3970e-01, -6.5144e-02,  6.6730e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.5197e-02,  5.0789e-02,  7.5180e-02],\n",
              "                        [-3.1159e-01, -1.6333e-01,  7.3458e-03],\n",
              "                        [ 7.2484e-03,  1.5027e-01, -2.4573e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.2697e-01,  2.4484e-01,  2.5748e-01],\n",
              "                        [-2.9219e-01,  2.5177e-01,  2.2001e-02],\n",
              "                        [ 9.8873e-02,  1.0546e-01,  2.6232e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.1929e-01, -2.9848e-01, -4.8383e-02],\n",
              "                        [ 1.9272e-01, -8.7131e-03,  1.5276e-01],\n",
              "                        [ 1.3719e-01,  4.0178e-02,  2.1413e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.3731e-01,  1.1005e-01, -8.7836e-02],\n",
              "                        [-2.4539e-01,  2.0884e-01, -8.6723e-02],\n",
              "                        [-1.6197e-01,  2.0213e-01, -2.0155e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.8461e-01,  3.2665e-01,  2.9909e-01],\n",
              "                        [ 3.4205e-02, -9.1266e-02, -5.5932e-02],\n",
              "                        [ 2.2312e-01,  2.4546e-02,  1.8202e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.0660e-01, -9.9320e-02,  2.5749e-03],\n",
              "                        [ 1.1821e-01, -1.9232e-01,  2.4221e-01],\n",
              "                        [ 2.2728e-01, -2.6654e-01, -1.3893e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.6764e-01,  2.2996e-01,  2.2804e-01],\n",
              "                        [-9.2346e-02, -2.5342e-01,  1.4029e-01],\n",
              "                        [-9.6223e-02,  1.7779e-01,  2.8902e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 2.8105e-01,  1.9402e-01, -1.8266e-01],\n",
              "                        [-1.4710e-01, -2.0081e-01,  1.3769e-01],\n",
              "                        [-9.1071e-02,  7.8828e-02, -2.3676e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 2.0496e-01,  8.3291e-02,  1.1016e-01],\n",
              "                        [-8.6608e-02, -2.5647e-02, -1.4727e-01],\n",
              "                        [ 1.2944e-01,  1.2891e-01,  9.6544e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 4.5523e-02,  7.1702e-02, -4.4746e-02],\n",
              "                        [ 2.0960e-01,  7.5594e-02, -3.2335e-02],\n",
              "                        [ 2.6803e-01,  2.3430e-01, -3.0922e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 3.6177e-02, -4.0697e-02, -2.8523e-01],\n",
              "                        [ 2.9068e-01, -6.4584e-02, -1.8311e-01],\n",
              "                        [-1.8678e-01,  2.8858e-01,  2.4947e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.9962e-01, -1.4512e-01, -2.6078e-01],\n",
              "                        [ 7.6124e-02,  2.9860e-03,  2.9290e-01],\n",
              "                        [-2.8671e-01,  2.7236e-01,  9.6992e-03]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.4659e-01, -2.5780e-01, -3.2286e-01],\n",
              "                        [-1.5073e-01,  2.9152e-01, -3.2261e-01],\n",
              "                        [ 2.2160e-01, -1.0672e-02,  2.3476e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 6.1677e-02,  2.6277e-01, -6.6414e-02],\n",
              "                        [ 1.6331e-02,  5.7301e-02,  2.4561e-01],\n",
              "                        [-2.4489e-01, -1.6852e-01,  9.8062e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.4499e-01, -2.8344e-01,  3.2134e-01],\n",
              "                        [ 2.1844e-01,  1.6569e-01,  1.4423e-01],\n",
              "                        [ 4.8488e-02, -2.4049e-01,  1.2422e-01]]],\n",
              "              \n",
              "              \n",
              "                      [[[ 1.0637e-01, -2.2552e-01, -6.7205e-02],\n",
              "                        [-3.1317e-01, -1.5651e-01, -1.8678e-01],\n",
              "                        [ 1.8254e-01,  1.4272e-01, -8.1192e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.7749e-02, -2.7018e-02,  4.4775e-02],\n",
              "                        [ 2.6738e-01, -1.2508e-01,  2.2112e-01],\n",
              "                        [ 4.9816e-03,  2.0000e-01, -2.9235e-01]]]])),\n",
              "             ('model.0.bias',\n",
              "              tensor([ 0.1594,  0.0937,  0.2636, -0.2422,  0.2277,  0.2366, -0.0226, -0.1122,\n",
              "                       0.1888,  0.2344, -0.2900, -0.0817,  0.3307, -0.2854, -0.1364,  0.0295,\n",
              "                      -0.2179, -0.1315,  0.1702,  0.2726,  0.1258, -0.2090, -0.1864, -0.1970,\n",
              "                      -0.1601,  0.0100, -0.0807, -0.2377,  0.1940, -0.2324,  0.1443, -0.2640])),\n",
              "             ('model.3.weight',\n",
              "              tensor([[[[ 1.8607e-02, -4.1856e-02, -1.2283e-02],\n",
              "                        [-5.3590e-02, -7.5896e-03, -3.1019e-02],\n",
              "                        [-4.5926e-02,  1.8563e-02, -5.0220e-02]],\n",
              "              \n",
              "                       [[-4.4595e-02,  2.2872e-03,  5.6824e-02],\n",
              "                        [ 4.1189e-02, -1.4446e-02,  4.1334e-02],\n",
              "                        [-5.8489e-03,  4.8830e-02, -5.7795e-02]],\n",
              "              \n",
              "                       [[ 4.2645e-02,  4.6519e-02,  2.9571e-02],\n",
              "                        [-5.0108e-02, -2.5953e-03,  9.6189e-03],\n",
              "                        [ 3.7614e-02, -5.5689e-02,  3.7564e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-2.9690e-02,  5.3301e-02, -2.9906e-02],\n",
              "                        [-5.8288e-02,  4.1501e-02,  7.6045e-04],\n",
              "                        [-1.9664e-02, -8.1364e-03,  2.8000e-02]],\n",
              "              \n",
              "                       [[ 4.5583e-02,  6.6607e-03, -2.2066e-02],\n",
              "                        [ 3.2195e-04, -1.0070e-02,  5.2124e-02],\n",
              "                        [ 1.2905e-02, -5.8003e-02, -3.9797e-02]],\n",
              "              \n",
              "                       [[-4.9299e-02,  5.3481e-02, -2.1334e-02],\n",
              "                        [ 5.5503e-02,  4.9056e-02, -4.5660e-02],\n",
              "                        [-3.8205e-02, -4.0189e-02,  5.3435e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-3.7458e-02, -5.2326e-02,  5.1984e-02],\n",
              "                        [ 1.6994e-02, -1.7512e-02,  2.0358e-02],\n",
              "                        [-1.1296e-02, -2.7639e-02, -3.7533e-02]],\n",
              "              \n",
              "                       [[-5.1953e-02, -3.8268e-02, -3.6936e-02],\n",
              "                        [ 5.3895e-02, -3.6594e-02,  5.5280e-02],\n",
              "                        [-4.8490e-02, -3.4023e-02,  1.1198e-03]],\n",
              "              \n",
              "                       [[-5.1924e-02, -3.8105e-02, -5.3472e-02],\n",
              "                        [ 4.9636e-02,  5.2368e-02,  3.8706e-02],\n",
              "                        [-2.6796e-02,  7.0680e-03, -5.7019e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.3139e-03,  4.3096e-02, -3.3377e-02],\n",
              "                        [ 7.2818e-03, -5.6063e-02, -1.2987e-02],\n",
              "                        [-1.0652e-02,  3.3140e-02,  1.5776e-02]],\n",
              "              \n",
              "                       [[-5.7698e-02,  5.8538e-02, -2.7516e-02],\n",
              "                        [-4.1741e-02,  5.5723e-02,  2.4103e-03],\n",
              "                        [-4.5337e-02, -2.7682e-02, -2.3370e-02]],\n",
              "              \n",
              "                       [[ 3.7941e-02, -4.2753e-02,  3.0152e-02],\n",
              "                        [-2.3281e-02, -4.0458e-02,  5.4279e-02],\n",
              "                        [ 3.5321e-02, -1.1238e-02,  3.6381e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-2.7133e-02, -1.1417e-02,  1.8213e-02],\n",
              "                        [-2.3990e-02,  1.6024e-02,  1.4020e-02],\n",
              "                        [ 2.3822e-02,  7.7587e-03,  5.8167e-02]],\n",
              "              \n",
              "                       [[ 4.5110e-03,  8.2207e-03, -1.0138e-02],\n",
              "                        [ 2.1441e-03, -3.9367e-02,  2.1872e-02],\n",
              "                        [ 2.2589e-03, -3.5776e-02, -1.3570e-02]],\n",
              "              \n",
              "                       [[-4.0795e-02, -2.0326e-02, -4.8552e-02],\n",
              "                        [-3.7782e-02, -4.1310e-02,  4.0164e-02],\n",
              "                        [-4.7798e-02, -2.1834e-03, -1.3897e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-5.1242e-02,  3.1267e-03,  2.0565e-02],\n",
              "                        [-4.7312e-02,  6.3354e-03, -3.9974e-02],\n",
              "                        [-1.2260e-02, -2.2767e-02, -3.8131e-02]],\n",
              "              \n",
              "                       [[-3.5561e-02, -4.0306e-02, -3.7330e-02],\n",
              "                        [-3.6462e-02,  9.9975e-03, -2.3251e-02],\n",
              "                        [ 5.4876e-02,  5.5325e-02,  2.8229e-02]],\n",
              "              \n",
              "                       [[ 2.7737e-02, -2.8243e-02,  2.6320e-02],\n",
              "                        [-3.3112e-02, -9.0952e-03,  6.2315e-03],\n",
              "                        [-3.2099e-02,  9.9837e-04,  4.4028e-02]]],\n",
              "              \n",
              "              \n",
              "                      ...,\n",
              "              \n",
              "              \n",
              "                      [[[-1.1765e-02, -1.2593e-02, -6.7135e-04],\n",
              "                        [ 2.7264e-02,  5.2390e-02, -1.1679e-02],\n",
              "                        [-5.5857e-02,  4.5670e-02,  2.3485e-02]],\n",
              "              \n",
              "                       [[ 3.7011e-02, -3.2326e-02, -3.4897e-02],\n",
              "                        [-1.1806e-02,  2.2306e-02, -5.6206e-02],\n",
              "                        [-4.2073e-02, -3.9528e-02, -1.3950e-02]],\n",
              "              \n",
              "                       [[-5.8905e-02,  2.7990e-02,  4.6907e-02],\n",
              "                        [-1.3625e-02,  1.9250e-02,  4.3946e-02],\n",
              "                        [-3.2109e-02,  5.8551e-03,  2.4177e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[ 2.7484e-02,  1.3869e-02,  2.9257e-02],\n",
              "                        [ 1.5370e-05, -1.3240e-02,  4.4719e-02],\n",
              "                        [-2.0472e-02,  4.1060e-02, -9.6110e-03]],\n",
              "              \n",
              "                       [[ 3.8416e-02, -3.4546e-02,  5.6703e-02],\n",
              "                        [-5.1259e-02, -1.1253e-02, -5.2551e-02],\n",
              "                        [-6.7846e-03,  5.8651e-02, -2.5363e-02]],\n",
              "              \n",
              "                       [[ 3.0037e-04, -5.8316e-02,  3.2181e-02],\n",
              "                        [-5.0164e-02,  2.3295e-02, -1.7118e-02],\n",
              "                        [-2.2099e-02, -2.6795e-04, -5.0869e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-1.6946e-02, -9.0767e-03, -2.1620e-03],\n",
              "                        [ 2.9838e-02, -2.7049e-02,  6.1010e-03],\n",
              "                        [-1.0425e-02, -1.8887e-03, -7.2099e-04]],\n",
              "              \n",
              "                       [[ 4.5068e-02, -5.5221e-02, -3.0947e-02],\n",
              "                        [ 2.1525e-02,  2.5211e-02,  2.1525e-02],\n",
              "                        [ 3.0937e-02,  3.8560e-02, -5.6301e-02]],\n",
              "              \n",
              "                       [[-3.3626e-02,  5.8018e-02,  4.6305e-02],\n",
              "                        [ 9.7596e-03,  2.0186e-02, -1.1842e-02],\n",
              "                        [ 2.0741e-02,  1.0752e-02, -1.4925e-02]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-3.2513e-02,  3.8513e-02, -3.9522e-02],\n",
              "                        [-4.7664e-02, -1.4747e-02, -5.4851e-02],\n",
              "                        [-5.0540e-02,  7.7061e-03,  5.1352e-03]],\n",
              "              \n",
              "                       [[-9.0554e-04, -3.3933e-02,  4.3049e-02],\n",
              "                        [ 5.3297e-02, -4.7073e-02,  4.4985e-02],\n",
              "                        [ 2.6677e-02, -2.2907e-02, -2.1896e-02]],\n",
              "              \n",
              "                       [[-9.0102e-04,  4.1818e-02, -2.5851e-02],\n",
              "                        [-7.9812e-03,  2.2557e-03,  2.7163e-03],\n",
              "                        [-4.5195e-02,  5.7767e-02,  4.7120e-02]]],\n",
              "              \n",
              "              \n",
              "                      [[[-3.5998e-02, -1.7609e-02,  8.5540e-03],\n",
              "                        [ 5.0032e-02, -2.3752e-02, -4.0150e-02],\n",
              "                        [-4.6688e-02, -5.1545e-03,  1.9728e-02]],\n",
              "              \n",
              "                       [[-1.6781e-03,  3.6972e-02,  2.1131e-02],\n",
              "                        [-2.9843e-03, -2.7151e-04,  2.0516e-02],\n",
              "                        [-1.3338e-03,  1.1489e-02, -3.5912e-02]],\n",
              "              \n",
              "                       [[ 5.5911e-02, -8.2390e-03, -7.7709e-03],\n",
              "                        [ 1.0870e-02,  5.5430e-02, -4.1043e-02],\n",
              "                        [ 1.9036e-02,  3.6711e-02,  1.6154e-03]],\n",
              "              \n",
              "                       ...,\n",
              "              \n",
              "                       [[-1.5790e-02, -2.5149e-02,  4.2070e-02],\n",
              "                        [-6.5421e-03,  3.8023e-02,  3.5231e-03],\n",
              "                        [ 4.3064e-03, -4.7353e-02, -1.8195e-02]],\n",
              "              \n",
              "                       [[-2.8208e-02,  6.8719e-03,  4.0831e-02],\n",
              "                        [-1.7749e-02, -3.8586e-02,  1.8342e-02],\n",
              "                        [-5.7307e-02, -2.5593e-02,  4.7059e-02]],\n",
              "              \n",
              "                       [[-5.6661e-02, -4.5249e-02,  3.7341e-02],\n",
              "                        [-2.3041e-02, -3.2561e-02, -3.7995e-02],\n",
              "                        [ 2.9679e-02, -4.0382e-02,  3.3070e-02]]]])),\n",
              "             ('model.3.bias',\n",
              "              tensor([ 0.0259,  0.0348,  0.0155,  0.0488,  0.0088,  0.0557, -0.0378,  0.0192,\n",
              "                      -0.0086,  0.0043,  0.0406,  0.0056,  0.0335, -0.0238,  0.0392, -0.0066,\n",
              "                       0.0094,  0.0494, -0.0272, -0.0411, -0.0193, -0.0380,  0.0562, -0.0266,\n",
              "                       0.0441, -0.0493,  0.0121,  0.0178, -0.0409, -0.0454,  0.0335, -0.0508,\n",
              "                       0.0206, -0.0553, -0.0233,  0.0134, -0.0063,  0.0520,  0.0528,  0.0172,\n",
              "                      -0.0524,  0.0426,  0.0396, -0.0083,  0.0249, -0.0465, -0.0114, -0.0529,\n",
              "                       0.0270, -0.0030,  0.0425,  0.0513,  0.0464, -0.0262, -0.0494,  0.0377,\n",
              "                      -0.0168, -0.0445, -0.0472,  0.0022,  0.0162, -0.0157,  0.0441,  0.0065])),\n",
              "             ('model.7.weight',\n",
              "              tensor([[-0.0358,  0.0447,  0.0130,  ..., -0.0250, -0.0393,  0.0538],\n",
              "                      [ 0.0395, -0.0360, -0.0297,  ..., -0.0509,  0.0272,  0.0362],\n",
              "                      [ 0.0178,  0.0624,  0.0551,  ..., -0.0189,  0.0155,  0.0479],\n",
              "                      ...,\n",
              "                      [ 0.0494, -0.0381,  0.0242,  ...,  0.0113,  0.0479,  0.0231],\n",
              "                      [-0.0446, -0.0107, -0.0230,  ...,  0.0435,  0.0175, -0.0621],\n",
              "                      [ 0.0469,  0.0457, -0.0567,  ...,  0.0127, -0.0577,  0.0068]])),\n",
              "             ('model.7.bias',\n",
              "              tensor([-2.9185e-02, -3.6676e-02,  2.3498e-02,  5.5181e-02,  4.8847e-02,\n",
              "                       1.5934e-02,  5.8176e-02,  1.3654e-02,  4.0036e-02,  2.8931e-02,\n",
              "                       4.0579e-03, -5.2901e-02, -5.9734e-03, -6.8947e-03,  3.5471e-02,\n",
              "                      -5.6546e-03, -1.0654e-02, -4.2958e-02, -3.4837e-02, -5.1491e-02,\n",
              "                       5.0415e-02,  3.9132e-03, -5.7452e-02,  4.9792e-02, -1.8521e-02,\n",
              "                      -4.7895e-04, -5.0683e-04,  3.0938e-03, -4.0093e-02, -4.0414e-02,\n",
              "                      -1.2393e-02, -4.0686e-02, -5.6687e-02,  2.8471e-02, -3.5683e-02,\n",
              "                      -5.8326e-02, -6.4910e-03, -4.8334e-02, -7.7411e-03,  5.5899e-03,\n",
              "                      -2.1770e-02, -4.7925e-02,  5.0646e-02,  6.2082e-02, -4.7178e-02,\n",
              "                      -3.9692e-02,  1.1060e-02,  4.6740e-02,  5.6248e-02, -3.6887e-02,\n",
              "                       4.3852e-02, -4.4542e-02,  5.8142e-02, -4.8313e-02, -2.5589e-02,\n",
              "                      -5.6342e-02,  1.6017e-03,  4.9508e-02, -5.1008e-02, -1.9898e-02,\n",
              "                      -3.5672e-03, -4.1556e-02, -3.1867e-02,  5.8109e-02, -5.6995e-02,\n",
              "                       4.5608e-02, -4.1274e-02, -3.6915e-02,  1.6058e-02,  6.1512e-02,\n",
              "                       8.0367e-03, -5.7657e-02, -3.0393e-02, -1.4903e-02,  5.7016e-03,\n",
              "                       3.9011e-05, -2.6295e-02, -2.0203e-02, -4.0748e-02,  6.7668e-03,\n",
              "                       2.3897e-03, -3.7714e-02,  6.1534e-02, -6.9044e-03,  1.6035e-02,\n",
              "                       4.3876e-03,  2.3117e-02,  2.3325e-02, -5.5948e-02,  8.1549e-03,\n",
              "                      -3.1730e-02,  3.6254e-02, -4.4184e-02, -6.1003e-02,  2.9592e-02,\n",
              "                      -2.1487e-03, -6.0693e-02, -2.5677e-02,  4.3904e-02,  1.3152e-02,\n",
              "                       4.8120e-02,  4.1055e-02,  6.0114e-02,  2.2427e-02,  5.0253e-02,\n",
              "                      -4.0721e-02, -5.9129e-02, -7.5436e-03,  2.0880e-02, -3.4584e-03,\n",
              "                      -2.0600e-02,  4.0958e-03, -1.4561e-02, -2.9922e-02, -3.5982e-02,\n",
              "                      -5.3395e-02,  1.0834e-02,  2.1570e-02,  2.9214e-02, -1.6166e-02,\n",
              "                      -2.8566e-02, -3.8314e-02, -5.6888e-02, -1.9175e-02, -4.3286e-02,\n",
              "                      -3.1668e-02, -4.7687e-02, -1.4970e-02,  1.3833e-02,  1.5319e-02,\n",
              "                      -2.5265e-02, -3.7832e-02,  4.4624e-02,  2.7995e-02, -1.7149e-03,\n",
              "                       5.4369e-02, -3.8486e-02, -4.4782e-02,  6.1683e-02, -5.6154e-02,\n",
              "                       4.1559e-02,  1.0062e-02,  4.9631e-02, -2.2501e-02, -4.4527e-02,\n",
              "                      -3.5024e-02, -1.0946e-03,  5.8463e-02, -1.3797e-02,  6.5291e-03,\n",
              "                      -2.0578e-02,  3.7306e-02,  2.2794e-02,  2.1438e-02, -1.3596e-03,\n",
              "                       2.1181e-02, -2.4583e-03, -4.4238e-02, -4.1528e-02,  4.7745e-02,\n",
              "                       2.3523e-02, -4.7914e-02,  5.2994e-02,  2.0544e-02, -5.6440e-02,\n",
              "                       3.6687e-02,  5.8421e-02,  6.5086e-03,  6.0692e-02, -3.3220e-03,\n",
              "                       1.1151e-02, -8.3094e-03, -3.0313e-02, -5.5541e-02, -4.7729e-03,\n",
              "                      -5.6046e-02,  5.2257e-02,  5.4812e-03, -1.1908e-02, -4.2503e-02,\n",
              "                       4.9925e-02, -3.7363e-02,  8.9605e-03, -1.4798e-02, -4.1706e-02,\n",
              "                       7.9108e-03,  6.0561e-02,  3.2678e-02, -5.5664e-02, -1.7888e-02,\n",
              "                      -9.6019e-03, -1.9856e-02, -4.3220e-02, -2.2874e-02, -1.2212e-02,\n",
              "                      -5.9936e-02, -4.4530e-02,  2.5861e-03, -5.2205e-02,  8.9566e-03])),\n",
              "             ('model.9.weight',\n",
              "              tensor([[ 0.0548,  0.0310,  0.0396,  ..., -0.0311, -0.0563, -0.0673],\n",
              "                      [ 0.0053, -0.0553,  0.0692,  ..., -0.0537, -0.0326,  0.0409],\n",
              "                      [-0.0429,  0.0394, -0.0190,  ...,  0.0410, -0.0432, -0.0105],\n",
              "                      ...,\n",
              "                      [-0.0017,  0.0007, -0.0428,  ...,  0.0044,  0.0157, -0.0265],\n",
              "                      [-0.0581, -0.0642,  0.0230,  ...,  0.0247, -0.0175,  0.0557],\n",
              "                      [ 0.0129,  0.0125, -0.0565,  ..., -0.0028,  0.0538, -0.0357]])),\n",
              "             ('model.9.bias',\n",
              "              tensor([ 0.0639, -0.0636,  0.0235, -0.0518, -0.0212, -0.0170,  0.0292,  0.0665,\n",
              "                       0.0508,  0.0669]))])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 107
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qNivdvbav0O8",
        "outputId": "35cfe41c-8bdf-487c-c273-48238cee8b3a"
      },
      "source": [
        "a= torch.Tensor([[2,1,3],[2,0,4]])\r\n",
        "\r\n",
        "class Parameter():\r\n",
        "  def __init__(self):\r\n",
        "    self."
      ],
      "execution_count": 123,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "torch.Size([2, 3])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 123
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "yDsHVkCNF5iP"
      },
      "source": [
        "def my_min(sequence, key_func=None):\r\n",
        "    \"\"\"\r\n",
        "    Return the maximum element of a sequence.\r\n",
        "    key_func is an optional one-argument ordering function.\r\n",
        "    \"\"\"\r\n",
        "    if not sequence:\r\n",
        "        raise ValueError('empty sequence')\r\n",
        "\r\n",
        "    if not key_func:\r\n",
        "        key_func = identity\r\n",
        "\r\n",
        "    minimum = sequence[0]\r\n",
        "\r\n",
        "    for item in sequence:\r\n",
        "        # Ask the key func which property to compare\r\n",
        "        if key_func(item) < key_func(minimum):\r\n",
        "            minimum = item\r\n",
        "\r\n",
        "    return minimum\r\n",
        "\r\n",
        "def weight(x):\r\n",
        "    return x[0]\r\n",
        "\r\n",
        "def plus_minus(x):\r\n",
        "  return 1 if x > 0 else -1"
      ],
      "execution_count": 117,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3nDbsMjCIAjG"
      },
      "source": [
        "def update_grad(update_info, global_params):\r\n",
        "  for grad in update_info:\r\n",
        "    if len(grad[2]) == 1:\r\n",
        "      global_params[grad[1]][grad[2][0]] += grad[0]*grad[3]\r\n",
        "    else:\r\n",
        "      global_params[grad[1]][grad[2][0]][grad[2][1]] += grad[0]*grad[3]"
      ],
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VJ-KCtPZfscP"
      },
      "source": [
        "def top_N_param_grad(param_grad, N):\r\n",
        "  abs_top_N = []\r\n",
        "\r\n",
        "  for i in range(N):\r\n",
        "    for j in range(len(param_grad['model.0.weight'][i])):\r\n",
        "      abs_top_N.append([abs(param_grad['model.0.weight'][i][j]), 'model.0.weight', [i,j], plus_minus(param_grad['model.0.weight'][i][j])])\r\n",
        "\r\n",
        "  minVal = min(abs_top_N)\r\n",
        "  for key in param_grad.keys():\r\n",
        "    for i in range(len(param_grad[key])):\r\n",
        "      if 'weight' in key:\r\n",
        "        for j in range(len(param_grad[key][i])):\r\n",
        "          if minVal[0] > abs(param_grad[key][i][j]):\r\n",
        "            abs_top_N.remove(minVal)\r\n",
        "            abs_top_N.append([abs(param_grad[key][i][j]), key, [i,j], plus_minus(param_grad[key][i][j])])\r\n",
        "            minVal = min(abs_top_N)\r\n",
        "      elif minVal[0] > abs(param_grad[key][i]):\r\n",
        "        abs_top_N.remove(minVal)\r\n",
        "        abs_top_N.append([abs(param_grad[key][i]), key, [i], plus_minus(param_grad[key][i])])\r\n",
        "        minVal = min(abs_top_N)\r\n",
        "\r\n",
        "  return abs_top_N"
      ],
      "execution_count": 109,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vnIZg2FIi-Fq"
      },
      "source": [
        "theta_u = 0.1\r\n",
        "threadLock = threading.Lock()\r\n",
        "exitFlag = 0\r\n",
        "\r\n",
        "\r\n",
        "class parameterServer():\r\n",
        "  def __init__(self, initial_params):\r\n",
        "    self.globalParams = initial_params.copy()\r\n",
        "    self.update_infos = []\r\n",
        "\r\n",
        "  def upload(self, update_info):\r\n",
        "    self.update_infos.append(update_info)\r\n",
        "  \r\n",
        "  def update(self):\r\n",
        "    print(\"server updating\")\r\n",
        "    for info in self.update_infos:\r\n",
        "      update_grad(info, self.globalParams)\r\n",
        "    self.update_info = []\r\n",
        "\r\n",
        "class edgeDevice():\r\n",
        "  def __init__(self, deviceID, server, initial_params, dataloader):\r\n",
        "    self.deviceID = deviceID\r\n",
        "    self.module = selfModule()\r\n",
        "    self.params = initial_params.copy()\r\n",
        "    self.server = server\r\n",
        "    self.dataloader = dataloader\r\n",
        "  \r\n",
        "  def train(self):\r\n",
        "      print(self.deviceID + \" ttraining\")\r\n",
        "\r\n",
        "      self.params = self.server.globalParams.copy()\r\n",
        "      self.module.load_state_dict(self.params)\r\n",
        "\r\n",
        "      criterion = nn.CrossEntropyLoss()\r\n",
        "      optimizer = torch.optim.SGD(self.module.parameters(), lr=0.01)\r\n",
        "\r\n",
        "      self.module.train()\r\n",
        "      train_loss = 0\r\n",
        "      total = 0\r\n",
        "      correct = 0\r\n",
        "\r\n",
        "      print(len(self.dataloader))\r\n",
        "\r\n",
        "      for batch_idx, data in enumerate(self.dataloader):\r\n",
        "          image, label = data\r\n",
        "          # Grad initialization\r\n",
        "          optimizer.zero_grad()\r\n",
        "          # Forward propagation\r\n",
        "          output = self.module(image)\r\n",
        "          # Calculate loss\r\n",
        "          loss = criterion(output, label)\r\n",
        "          # Backprop\r\n",
        "          loss.backward()\r\n",
        "          # Weight update\r\n",
        "          optimizer.step()\r\n",
        "          \r\n",
        "          train_loss += loss.item()\r\n",
        "\r\n",
        "          _,predicted = output.max(1)\r\n",
        "          total += label.size(0)\r\n",
        "          correct += predicted.eq(label).sum().item()\r\n",
        "        \r\n",
        "          if (batch_idx+1) % 1000 == 0:\r\n",
        "            print(\"Step: {}/{} | train_loss: {:.4f} | Acc:{:.3f}%\".format(batch_idx+1, len(self.dataloader), train_loss/1000, 100.*correct/total))\r\n",
        "\r\n",
        "      param_grads = {key: self.module.state_dict()[key] - self.params[key] for key in self.params.keys()}\r\n",
        "      top_grads = top_N_param_grad(param_grads,3)\r\n",
        "      self.server.upload(top_grads)"
      ],
      "execution_count": 68,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LBan9EASeqM0"
      },
      "source": [
        "device_num = 4\r\n",
        "batch_size = 2\r\n",
        "\r\n",
        "trainset = torchvision.datasets.MNIST(root='./data', train=True, download=True, transform=transforms.ToTensor())\r\n",
        "\r\n",
        "traindata_split = torch.utils.data.random_split(trainset, [int(trainset.data.shape[0] / device_num) for _ in range(device_num)])\r\n",
        "\r\n",
        "# Creating a pytorch loader for a Deep Learning model\r\n",
        "train_loader = [torch.utils.data.DataLoader(x, batch_size=batch_size, shuffle=True) for x in traindata_split]\r\n",
        "\r\n",
        "\r\n",
        "testset = torchvision.datasets.MNIST(root='./data', train=False, download=True, transform=transforms.ToTensor())\r\n",
        "testloader = torch.utils.data.DataLoader(testset, batch_size=10, shuffle=False)\r\n",
        "\r\n",
        "# Download mnist data in ./data folder"
      ],
      "execution_count": 69,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "qYKIogcmqpWz",
        "outputId": "79bf11e7-d824-4126-a228-074fd5b82882"
      },
      "source": [
        "for batch_idx, data in enumerate(train_loader[0]):\r\n",
        "  image, label = data\r\n",
        "  print(image.size())\r\n",
        "  if batch_idx == 2:\r\n",
        "    break"
      ],
      "execution_count": 75,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "torch.Size([2, 1, 28, 28])\n",
            "torch.Size([2, 1, 28, 28])\n",
            "torch.Size([2, 1, 28, 28])\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2gNqDO9vfLNX",
        "outputId": "790b3564-353a-421b-8132-fbb3ee649023"
      },
      "source": [
        "len(trainloader)"
      ],
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "6000"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 818
        },
        "id": "10eZpadndskp",
        "outputId": "70b40b08-34f2-4ead-fca4-6d9e07d18a1e"
      },
      "source": [
        "num_of_device_in_round = 2\r\n",
        "\r\n",
        "initialmodel = selfModule()\r\n",
        "\r\n",
        "initial_params = initialmodel.state_dict()\r\n",
        "\r\n",
        "server = parameterServer(initial_params)\r\n",
        "\r\n",
        "devices = []\r\n",
        "\r\n",
        "for i in range(device_num):\r\n",
        "  devices.append(edgeDevice('device-'+str(i), server, initial_params, train_loader[i]))\r\n",
        "\r\n",
        "for i in range(5):\r\n",
        "  devices_selected = np.random.permutation(np.arange(device_num))[:num_of_device_in_round]\r\n",
        "  print(devices_selected)\r\n",
        "  for de_num in devices_selected:\r\n",
        "    devices[de_num].train()\r\n",
        "  server.update()"
      ],
      "execution_count": 110,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[1 3]\n",
            "device-1 ttraining\n",
            "7500\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/torch/nn/modules/container.py:117: UserWarning: Implicit dimension choice for log_softmax has been deprecated. Change the call to include dim=X as an argument.\n",
            "  input = module(input)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "Step: 1000/7500 | train_loss: 1.9822 | Acc:38.850%\n",
            "Step: 2000/7500 | train_loss: 2.8601 | Acc:56.625%\n",
            "Step: 3000/7500 | train_loss: 3.3720 | Acc:65.867%\n",
            "Step: 4000/7500 | train_loss: 3.7704 | Acc:71.450%\n",
            "Step: 5000/7500 | train_loss: 4.0803 | Acc:75.380%\n",
            "Step: 6000/7500 | train_loss: 4.3601 | Acc:78.042%\n",
            "Step: 7000/7500 | train_loss: 4.6066 | Acc:80.129%\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "error",
          "ename": "RuntimeError",
          "evalue": "ignored",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m                              Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-110-56cbc0c0ba2c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     16\u001b[0m   \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdevices_selected\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     17\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mde_num\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdevices_selected\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 18\u001b[0;31m     \u001b[0mdevices\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mde_num\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     19\u001b[0m   \u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-68-69f90caa6905>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m     65\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     66\u001b[0m       \u001b[0mparam_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m{\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmodule\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m-\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mkey\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mparams\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mkeys\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m}\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 67\u001b[0;31m       \u001b[0mtop_grads\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtop_N_param_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grads\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;36m3\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     68\u001b[0m       \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mserver\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupload\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtop_grads\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-109-1e671de2d8f1>\u001b[0m in \u001b[0;36mtop_N_param_grad\u001b[0;34m(param_grad, N)\u001b[0m\n\u001b[1;32m      4\u001b[0m   \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mN\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      5\u001b[0m     \u001b[0;32mfor\u001b[0m \u001b[0mj\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.0.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 6\u001b[0;31m       \u001b[0mabs_top_N\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mabs\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.0.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'model.0.weight'\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mplus_minus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mparam_grad\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m'model.0.weight'\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mi\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mj\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      7\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      8\u001b[0m   \u001b[0mminVal\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mabs_top_N\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m<ipython-input-9-5fcea3d29b0c>\u001b[0m in \u001b[0;36mplus_minus\u001b[0;34m(x)\u001b[0m\n\u001b[1;32m     23\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m \u001b[0;32mdef\u001b[0m \u001b[0mplus_minus\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 25\u001b[0;31m   \u001b[0;32mreturn\u001b[0m \u001b[0;36m1\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mx\u001b[0m \u001b[0;34m>\u001b[0m \u001b[0;36m0\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mRuntimeError\u001b[0m: Boolean value of Tensor with more than one value is ambiguous"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "djfOWN1uMMgB"
      },
      "source": [
        "import Queue\r\n",
        "import threading\r\n",
        "import time\r\n",
        "\r\n",
        "exitFlag = 0\r\n",
        "\r\n",
        "class myThread (threading.Thread):\r\n",
        "   def __init__(self, threadID, name, q, device):\r\n",
        "      threading.Thread.__init__(self)\r\n",
        "      self.threadID = threadID\r\n",
        "      self.name = name\r\n",
        "      self.q = q\r\n",
        "      self.device = device\r\n",
        "   def run(self):\r\n",
        "      print \"Starting \" + self.name\r\n",
        "      process(self.name, self.q)\r\n",
        "      print \"Exiting \" + self.name\r\n",
        "\r\n",
        "def process_data(threadName, q):\r\n",
        "   while not exitFlag:\r\n",
        "      queueLock.acquire()\r\n",
        "         if not workQueue.empty():\r\n",
        "            data = q.get()\r\n",
        "            queueLock.release()\r\n",
        "            print \"%s processing %s\" % (threadName, data)\r\n",
        "         else:\r\n",
        "            queueLock.release()\r\n",
        "         time.sleep(1)"
      ],
      "execution_count": null,
      "outputs": []
    }
  ]
}